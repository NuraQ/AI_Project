{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB8pV9xczh6P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image\n",
        "\n",
        "MODEL_NAME = 'google/vit-base-patch16-224'\n",
        "NUM_CLASSES = 2\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "DATA_DIR = \"/content/gdrive/MyDrive/eeg_8x8_chunks\"\n",
        "\n",
        "VALID_CLASSES = {4, 5}\n",
        "LABEL_MAP = {4: 0, 5: 1}\n",
        "\n",
        "def extract_subject_id(fname):\n",
        "    m = re.search(r\"S\\d{3}\", fname)\n",
        "    if m:\n",
        "        return m.group(0)\n",
        "    if fname.startswith(\"sample\"):\n",
        "        try:\n",
        "            return fname.split(\"_\")[1][:4]\n",
        "        except Exception:\n",
        "            return \"UNK\"\n",
        "    return \"UNK\"\n",
        "\n",
        "def get_subject_ids():\n",
        "    ids = set()\n",
        "    for fname in os.listdir(DATA_DIR):\n",
        "        if fname.endswith(\".npz\") and fname.startswith(\"sample\"):\n",
        "            sid = extract_subject_id(fname)\n",
        "            if sid != \"UNK\":\n",
        "                ids.add(sid)\n",
        "    return sorted(ids)\n",
        "\n",
        "def _slice(lst, a, b):\n",
        "    a = min(a, len(lst)); b = min(b, len(lst))\n",
        "    return lst[a:b]\n",
        "\n",
        "def load_chunks_by_subject_ids(subject_ids):\n",
        "    X_all, y_all = [], []\n",
        "    files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".npz\") and f.startswith(\"sample\")]\n",
        "    for sid in subject_ids:\n",
        "        sid_token = f\"_{sid}R\"\n",
        "        sid_files = [f for f in files if sid_token in f]\n",
        "        for fname in sid_files:\n",
        "            path = os.path.join(DATA_DIR, fname)\n",
        "            data = np.load(path, allow_pickle=True)\n",
        "            X, y = data[\"X\"], data[\"y\"]\n",
        "            if isinstance(y, np.ndarray):\n",
        "                y = y.item()\n",
        "            if y not in VALID_CLASSES:\n",
        "                continue\n",
        "            if X.ndim != 3 or X.shape[1] != 8 or X.shape[2] != 8:\n",
        "                continue\n",
        "            X_all.append(X.astype(np.float32))\n",
        "            y_all.append(LABEL_MAP[y])\n",
        "    if not X_all:\n",
        "        raise RuntimeError(\"No samples after subject-based loading.\")\n",
        "    X_all = np.stack(X_all)\n",
        "    y_all = np.array(y_all, dtype=int)\n",
        "    return X_all, y_all\n",
        "\n",
        "subject_ids = get_subject_ids()\n",
        "train_ids = _slice(subject_ids, 0, 70)\n",
        "dev_ids   = _slice(subject_ids, 71, 86)\n",
        "test_ids  = _slice(subject_ids, 87, 103)\n",
        "\n",
        "X_train, y_train = load_chunks_by_subject_ids(train_ids)\n",
        "X_dev,   y_dev   = load_chunks_by_subject_ids(dev_ids)\n",
        "X_test,  y_test  = load_chunks_by_subject_ids(test_ids)\n",
        "\n",
        "print(\"Data Shapes:\")\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Dev:\",   X_dev.shape,   y_dev.shape)\n",
        "print(\"Test:\",  X_test.shape,  y_test.shape)\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(MODEL_NAME)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "])\n",
        "\n",
        "class EEGImageDataset(Dataset):\n",
        "    def __init__(self, X, y, transform):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.X[idx]\n",
        "        img = torch.tensor(img).float()\n",
        "        img = torch.mean(img, dim=0, keepdim=True)\n",
        "        img = img.repeat(3, 1, 1)\n",
        "        img = img.permute(1, 2, 0).numpy()\n",
        "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
        "        img = self.transform(img)\n",
        "        return {\"pixel_values\": img, \"labels\": torch.tensor(self.y[idx], dtype=torch.long)}\n",
        "\n",
        "train_dataset = EEGImageDataset(X_train, y_train, transform)\n",
        "dev_dataset   = EEGImageDataset(X_dev,   y_dev,   transform)\n",
        "test_dataset  = EEGImageDataset(X_test,  y_test,  transform)\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(MODEL_NAME, num_labels=11, ignore_mismatched_sizes=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit_pretrained_results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    num_train_epochs=40,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    learning_rate=5e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=1,\n",
        ")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(pred.label_ids, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=feature_extractor\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nFinal Evaluation\")\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(test_results)\n",
        "\n",
        "model.save_pretrained(\"vit_pretrained_model\")\n",
        "print(\"Saved pretrained ViT model.\")\n"
      ]
    }
  ]
}