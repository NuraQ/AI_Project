{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtXrtZi9pbNd"
      },
      "outputs": [],
      "source": [
        "# ===== ViT (3-band from 5) EEG Topomaps â€” subject-independent split =====\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision.transforms import functional as TF\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "from transformers import AutoConfig, ViTForImageClassification, TrainingArguments, Trainer, set_seed\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
        "    matthews_corrcoef, cohen_kappa_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "DATA_DIR = \"/content/gdrive/MyDrive/1segment_topomap_5channel_11classes\"\n",
        "RESULTS_ROOT = \"./vit_topomap_results_sweep\"\n",
        "os.makedirs(RESULTS_ROOT, exist_ok=True)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 60\n",
        "NUM_CLASSES = 4\n",
        "IMAGE_SIZE_FOR_VIT = 224         # vit-base-patch16-224\n",
        "RANDOM_SEED = 42\n",
        "MODEL_NAME = \"google/vit-base-patch16-224-in21k\"  # native 3-channel ViT\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\">> Device: {device}\")\n",
        "\n",
        "\n",
        "# Use ONLY three bands: theta, alpha, beta (indices 1,2,3)\n",
        "THREE_BAND_IDX = [1, 2, 3]  # 0=delta,1=theta,2=alpha,3=beta,4=gamma\n",
        "\n",
        "EXCLUDED_SUBJECTS = {\"S038\", \"S088\", \"S089\", \"S092\", \"S100\", \"S104\"}\n",
        "\n",
        "def get_subject_ids():\n",
        "    ids = set()\n",
        "    for fname in os.listdir(DATA_DIR):\n",
        "        if fname.endswith(\".npz\") and fname.startswith(\"sample\"):\n",
        "            # e.g., sample_S001R01_chunk00.npz -> 'S001'\n",
        "            sid = fname.split('_')[1][:4]\n",
        "            if sid not in EXCLUDED_SUBJECTS:\n",
        "                ids.add(sid)\n",
        "    return sorted(ids)\n",
        "\n",
        "subject_ids = get_subject_ids()\n",
        "random.seed(RANDOM_SEED)\n",
        "random.shuffle(subject_ids)\n",
        "\n",
        "def _slice(lst, a, b):\n",
        "    a = min(a, len(lst)); b = min(b, len(lst))\n",
        "    return lst[a:b]\n",
        "\n",
        "# Same slicing pattern you used before\n",
        "train_ids = _slice(subject_ids, 0, 70)\n",
        "dev_ids   = _slice(subject_ids, 70, 85)\n",
        "test_ids  = _slice(subject_ids, 85, 101)\n",
        "\n",
        "print(f\">> Subjects total={len(subject_ids)} | train={len(train_ids)} dev={len(dev_ids)} test={len(test_ids)}\")\n",
        "print(\"   train_ids[:5]:\", train_ids[:5])\n",
        "\n",
        "# Label mapping (kept as-is)\n",
        "LABEL_MAP = {2: 0, 3: 1, 6: 2, 7: 1}\n",
        "VALID_CLASSES = set(LABEL_MAP.keys())\n",
        "\n",
        "def load_chunks_by_subject_ids(subject_ids):\n",
        "    \"\"\"\n",
        "    Load chunk files for the provided subjects ONLY.\n",
        "    - Select bands [theta, alpha, beta] -> (3,H,W)\n",
        "    - Per-chunk normalize AFTER selection\n",
        "    - Keep labels in VALID_CLASSES and map using LABEL_MAP\n",
        "    Returns: X (N,3,H,W) float32, y (N,) int\n",
        "    \"\"\"\n",
        "    X_all, y_all = [], []\n",
        "    files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".npz\") and f.startswith(\"sample\")]\n",
        "\n",
        "    for sid in subject_ids:\n",
        "        sid_token = f\"_{sid}R\"  # matches ..._S001R01_...\n",
        "        sid_files = [f for f in files if sid_token in f]\n",
        "        if not sid_files:\n",
        "            continue\n",
        "        print(f\"   {sid}: {len(sid_files)} files (e.g., {sid_files[:2]})\")\n",
        "\n",
        "        for fname in sid_files:\n",
        "            path = os.path.join(DATA_DIR, fname)\n",
        "            data = np.load(path)\n",
        "            X, y = data[\"X\"], data[\"y\"]\n",
        "\n",
        "            if isinstance(y, np.ndarray):\n",
        "                y = y.item()\n",
        "\n",
        "            if y not in VALID_CLASSES:\n",
        "                continue\n",
        "\n",
        "            # Need at least up to band index 3\n",
        "            if X.ndim != 3 or X.shape[0] <= max(THREE_BAND_IDX):\n",
        "                continue\n",
        "\n",
        "            # Select 3 bands, then normalize per-chunk\n",
        "            X = X[THREE_BAND_IDX, :, :]                 # (3,H,W)\n",
        "            X = (X - X.mean()) / (X.std() + 1e-8)\n",
        "\n",
        "            X_all.append(X.astype(np.float32))\n",
        "            y_all.append(LABEL_MAP[y])\n",
        "\n",
        "    if not X_all:\n",
        "        raise RuntimeError(\"No samples after subject-based loading. Check DATA_DIR and subject IDs.\")\n",
        "\n",
        "    X_all = np.stack(X_all)             # (N, 3, H, W)\n",
        "    y_all = np.array(y_all, dtype=int)  # (N,)\n",
        "    return X_all, y_all\n",
        "\n",
        "X_train, y_train = load_chunks_by_subject_ids(train_ids)\n",
        "X_val,   y_val   = load_chunks_by_subject_ids(dev_ids)\n",
        "X_test,  y_test  = load_chunks_by_subject_ids(test_ids)\n",
        "\n",
        "print(\"  Data Shapes (3 bands):\")\n",
        "print(\"   Train:\", X_train.shape, y_train.shape)\n",
        "print(\"   Val  :\", X_val.shape,   y_val.shape)\n",
        "print(\"   Test :\", X_test.shape,  y_test.shape)\n",
        "print(\"   Class counts train:\", {int(c): int((y_train==c).sum()) for c in np.unique(y_train)})\n",
        "\n",
        "\n",
        "def resize_224(x: torch.Tensor) -> torch.Tensor:\n",
        "    # x: (C,H,W) float tensor\n",
        "    x = x.unsqueeze(0)  # (1,C,H,W)\n",
        "    x = F.interpolate(\n",
        "        x, size=(IMAGE_SIZE_FOR_VIT, IMAGE_SIZE_FOR_VIT),\n",
        "        mode=\"bilinear\", align_corners=False\n",
        "    )\n",
        "    return x.squeeze(0)  # (C,224,224)\n",
        "\n",
        "class TensorAug:\n",
        "    \"\"\"Tensor-native augmentation that works with C=3 (no PIL).\"\"\"\n",
        "    def __init__(self, do_aug=True, max_rotate=15.0, hflip_p=0.5):\n",
        "        self.do_aug = do_aug\n",
        "        self.max_rotate = max_rotate\n",
        "        self.hflip_p = hflip_p\n",
        "\n",
        "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = resize_224(x)\n",
        "        if not self.do_aug:\n",
        "            return x\n",
        "\n",
        "        if torch.rand(1).item() < self.hflip_p:\n",
        "            x = torch.flip(x, dims=[2])  # flip width (C,H,W) -> W axis\n",
        "\n",
        "        angle = (torch.rand(1).item() * 2 * self.max_rotate) - self.max_rotate\n",
        "        x = TF.rotate(x, angle, interpolation=InterpolationMode.BILINEAR, expand=False)\n",
        "        return x\n",
        "\n",
        "train_transform = TensorAug(do_aug=True)\n",
        "eval_transform  = TensorAug(do_aug=False)\n",
        "\n",
        "\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx])  # (C,H,W) float32\n",
        "        y = torch.tensor(self.y[idx]).long()\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "        # print on first few calls only\n",
        "        if idx < 1:\n",
        "            print(f\"[EEGDataset] idx={idx} x.shape={tuple(x.shape)} y={int(y)}\")\n",
        "        return {\"pixel_values\": x, \"labels\": y}\n",
        "\n",
        "train_ds = EEGDataset(X_train, y_train, transform=train_transform)\n",
        "val_ds   = EEGDataset(X_val,   y_val,   transform=eval_transform)\n",
        "test_ds  = EEGDataset(X_test,  y_test,  transform=eval_transform)\n",
        "\n",
        "\n",
        "class_weights_np = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "CLASS_WEIGHTS_TENSOR = torch.tensor(class_weights_np, dtype=torch.float32)\n",
        "print(\">> Class weights (train):\", CLASS_WEIGHTS_TENSOR.tolist())\n",
        "\n",
        "def build_sampler(y_array):\n",
        "    cw = compute_class_weight('balanced', classes=np.unique(y_array), y=y_array)\n",
        "    sample_weights = torch.tensor(cw, dtype=torch.float32)[torch.tensor(y_array, dtype=torch.long)]\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights,\n",
        "                                    num_samples=len(sample_weights),\n",
        "                                    replacement=True)\n",
        "    return sampler\n",
        "\n",
        "\n",
        "def compute_full_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(p.predictions), dim=-1).numpy()\n",
        "\n",
        "    y_true = p.label_ids\n",
        "    if y_true.ndim > 1:\n",
        "        y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "    try:\n",
        "        if probs.shape[1] == 2:\n",
        "            auc = roc_auc_score(y_true, probs[:, 1])\n",
        "        else:\n",
        "            auc = roc_auc_score(y_true, probs, multi_class='ovr', average='weighted')\n",
        "    except Exception:\n",
        "        auc = float('nan')\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, preds),\n",
        "        \"auc\": auc,\n",
        "        \"precision_weighted\": precision_score(y_true, preds, average=\"weighted\", zero_division=0),\n",
        "        \"recall_weighted\": recall_score(y_true, preds, average=\"weighted\", zero_division=0),\n",
        "        \"f1_weighted\": f1_score(y_true, preds, average=\"weighted\", zero_division=0),\n",
        "        \"precision_macro\": precision_score(y_true, preds, average=\"macro\", zero_division=0),\n",
        "        \"recall_macro\": recall_score(y_true, preds, average=\"macro\", zero_division=0),\n",
        "        \"f1_macro\": f1_score(y_true, preds, average=\"macro\", zero_division=0),\n",
        "        \"matthews_corrcoef\": matthews_corrcoef(y_true, preds),\n",
        "        \"cohen_kappa\": cohen_kappa_score(y_true, preds),\n",
        "    }\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, use_weighted_sampler=False, train_labels=None, train_batch_size=32, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "        self.use_weighted_sampler = use_weighted_sampler\n",
        "        self.train_labels = train_labels\n",
        "        self.train_batch_size = train_batch_size\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        pixel_values = inputs.get(\"pixel_values\")\n",
        "        if pixel_values.ndim == 3:\n",
        "            # (C,H,W) -> (B=1,C,H,W) for safety\n",
        "            pixel_values = pixel_values.unsqueeze(0)\n",
        "        # debug occasionally\n",
        "        if torch.rand(1).item() < 0.0005:\n",
        "            print(f\"[compute_loss] pixel_values batch shape: {tuple(pixel_values.shape)} (expect B,3,224,224)\")\n",
        "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        if self.class_weights is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(model.device))\n",
        "        else:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        if not self.use_weighted_sampler:\n",
        "            return super().get_train_dataloader()\n",
        "\n",
        "        sampler = build_sampler(self.train_labels)\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.train_batch_size,\n",
        "            sampler=sampler,\n",
        "            collate_fn=self.data_collator,\n",
        "            drop_last=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "def load_vit_3ch(num_labels):\n",
        "    \"\"\"\n",
        "    Use the standard ImageNet-21k ViT (expects 3-channel inputs).\n",
        "    No patch-embed surgery needed since we now feed 3 bands.\n",
        "    \"\"\"\n",
        "    model = ViTForImageClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "    print(f\" model.config.num_channels: {model.config.num_channels} (expect 3)\")\n",
        "    print(f\"Noura hidden_size              : {model.config.hidden_size}\")\n",
        "    return model\n",
        "\n",
        "# ==============================\n",
        "# ---- Single run executor  ----\n",
        "# ==============================\n",
        "def run_experiment(run_cfg):\n",
        "    seed = run_cfg.get(\"seed\", RANDOM_SEED)\n",
        "    set_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    run_name = run_cfg.get(\"run_name\", f\"run_{int(time.time())}\")\n",
        "    out_dir  = os.path.join(RESULTS_ROOT, run_name)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\n========== RUN: {run_name} ==========\")\n",
        "    print(\"Config:\", json.dumps(run_cfg, indent=2))\n",
        "\n",
        "    # datasets with chosen transforms\n",
        "    tr_transform = train_transform if run_cfg.get(\"augment\", True) else TensorAug(do_aug=False)\n",
        "    train_ds = EEGDataset(X_train, y_train, transform=tr_transform)\n",
        "    val_ds   = EEGDataset(X_val,   y_val,   transform=eval_transform)\n",
        "    test_ds  = EEGDataset(X_test,  y_test,  transform=eval_transform)\n",
        "\n",
        "    # -------- Model: ViT (3-channel) ----------\n",
        "    model = load_vit_3ch(num_labels=NUM_CLASSES).to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tmp = train_ds[0][\"pixel_values\"].unsqueeze(0).to(device)\n",
        "        print(f\" Dry-run input shape: {tuple(tmp.shape)} (expect (1,3,224,224))\")\n",
        "        out = model(pixel_values=tmp)\n",
        "        print(f\" Dry-run logits shape: {tuple(out.logits.shape)} (expect (1,{NUM_CLASSES}))\")\n",
        "\n",
        "    if run_cfg.get(\"freeze_backbone\", False):\n",
        "        frozen, trainable = 0, 0\n",
        "        for name, p in model.named_parameters():\n",
        "            if name.startswith(\"vit.encoder\") or name.startswith(\"vit.embeddings\"):\n",
        "                p.requires_grad = False\n",
        "                frozen += p.numel()\n",
        "            else:\n",
        "                trainable += p.numel()\n",
        "        print(f\">> Frozen params: {frozen:,} | Trainable params: {trainable:,}\")\n",
        "\n",
        "    label_smoothing = float(run_cfg.get(\"label_smoothing\", 0.0))\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=out_dir,\n",
        "        per_device_train_batch_size=run_cfg.get(\"batch_size\", BATCH_SIZE),\n",
        "        per_device_eval_batch_size=run_cfg.get(\"batch_size\", BATCH_SIZE),\n",
        "        num_train_epochs=run_cfg.get(\"epochs\", EPOCHS),\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=run_cfg.get(\"lr\", 1e-5),\n",
        "        weight_decay=run_cfg.get(\"weight_decay\", 0.01),\n",
        "        load_best_model_at_end=True,\n",
        "        logging_steps=10,\n",
        "        report_to=\"none\",\n",
        "        metric_for_best_model=\"eval_f1_weighted\",\n",
        "        greater_is_better=True,\n",
        "        seed=seed,\n",
        "        label_smoothing_factor=label_smoothing,\n",
        "        gradient_accumulation_steps=run_cfg.get(\"grad_accum\", 1),\n",
        "        lr_scheduler_type=run_cfg.get(\"lr_schedule\", \"cosine\"),\n",
        "        warmup_ratio=run_cfg.get(\"warmup_ratio\", 0.0),\n",
        "        dataloader_num_workers=2,\n",
        "        save_total_limit=2\n",
        "    )\n",
        "\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        compute_metrics=compute_full_metrics,\n",
        "        class_weights=CLASS_WEIGHTS_TENSOR,\n",
        "        use_weighted_sampler=run_cfg.get(\"weighted_sampler\", False),\n",
        "        train_labels=y_train,\n",
        "        train_batch_size=run_cfg.get(\"batch_size\", BATCH_SIZE),\n",
        "    )\n",
        "\n",
        "    print(\">> Starting training ...\")\n",
        "    trainer.train()\n",
        "    print(\">> Training done.\")\n",
        "\n",
        "    def eval_split(ds, split_name):\n",
        "        print(f\">> Evaluating: {split_name}\")\n",
        "        metrics = trainer.evaluate(eval_dataset=ds)\n",
        "        clean = {k.replace(\"eval_\", \"\"): float(v) for k, v in metrics.items() if k.startswith(\"eval_\")}\n",
        "        preds_out = trainer.predict(ds)\n",
        "        preds = np.argmax(preds_out.predictions, axis=1)\n",
        "        y_true = preds_out.label_ids\n",
        "        cm = confusion_matrix(y_true, preds).tolist()\n",
        "        cr = classification_report(y_true, preds, zero_division=0)\n",
        "        clean[\"confusion_matrix\"] = cm\n",
        "        clean[\"classification_report\"] = cr\n",
        "        print(f\"   {split_name} acc={clean.get('accuracy'):.4f} f1_w={clean.get('f1_weighted'):.4f}\")\n",
        "        return clean\n",
        "\n",
        "    results = {\n",
        "        \"config\": run_cfg,\n",
        "        \"train_metrics\": eval_split(train_ds, \"train\"),\n",
        "        \"val_metrics\":   eval_split(val_ds, \"val\"),\n",
        "        \"test_metrics\":  eval_split(test_ds, \"test\"),\n",
        "    }\n",
        "\n",
        "    # save json\n",
        "    with open(os.path.join(out_dir, \"results.json\"), \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"Finished {run_name}. Results saved to {out_dir}\")\n",
        "    return results\n",
        "\n",
        "\n",
        "SWEEP = [\n",
        "      # {\n",
        "      #   \"run_name\": \"S1_reg_ema_es\",\n",
        "      #   \"lr\": 2e-5, \"weight_decay\": 0.02, \"batch_size\": 32, \"epochs\": 100,\n",
        "      #   \"augment\": True, \"weighted_sampler\": True, \"freeze_backbone\": False,\n",
        "      #   \"label_smoothing\": 0.10, \"lr_schedule\": \"cosine_with_restarts\",\n",
        "      #   \"num_cycles\": 5, \"warmup_ratio\": 0.15, \"ema_decay\": 0.999,\n",
        "      #   \"early_stopping\": {\"metric\": \"macro_f1\", \"patience\": 10}\n",
        "      # },\n",
        "      # {\n",
        "      #   \"run_name\": \"S2_llrd\",\n",
        "      #   \"lr\": 2e-5, \"head_lr\": 5e-5, \"layer_decay\": 0.75,\n",
        "      #   \"True\": 0.02, \"batch_size\": 32, \"epochs\": 80,\n",
        "      #   \"augment\": True, \"weighted_sampler\": True, \"freeze_backbone\": False,\n",
        "      #   \"label_smoothing\": 0.05, \"lr_schedule\": \"cosine\", \"warmup_ratio\": 0.10\n",
        "      # },\n",
        "      {\"run_name\": \"A_baseline_lr1e-5_b32_e60_wd0.01_augY_freezeN\",\n",
        "      \"lr\": 1e-5, \"weight_decay\": 0.01, \"batch_size\": 32, \"epochs\": 60,\n",
        "      \"augment\": True, \"weighted_sampler\": False, \"freeze_backbone\": False,\n",
        "      \"label_smoothing\": 0.0, \"lr_schedule\": \"cosine\", \"warmup_ratio\": 0.0, \"seed\": 42},\n",
        "\n",
        "      {\"run_name\": \"S_lr3e-5_b64_e60_wd0.01_augY_freezeN_ls0.05\",\n",
        "      \"lr\": 3e-5, \"weight_decay\": 0.01, \"batch_size\": 64, \"epochs\": 60,\n",
        "      \"augment\": True, \"weighted_sampler\": False, \"freeze_backbone\": False,\n",
        "      \"label_smoothing\": 0.05, \"lr_schedule\": \"cosine\", \"warmup_ratio\": 0.05, \"seed\": 42},\n",
        "\n",
        "      {\"run_name\": \"S_lr2e-5_b32_e80_wd0.01_augY_freezeN_sampler\",\n",
        "      \"lr\": 2e-5, \"weight_decay\": 0.01, \"batch_size\": 32, \"epochs\": 80,\n",
        "      \"augment\": True, \"weighted_sampler\": True, \"freeze_backbone\": False,\n",
        "      \"label_smoothing\": 0.05, \"lr_schedule\": \"cosine\", \"warmup_ratio\": 0.1, \"seed\": 123},\n",
        "\n",
        "      {\"run_name\": \"S_freeze_lr5e-5_b64_e40_wd0.02_augY_freezeY\",\n",
        "      \"lr\": 5e-5, \"weight_decay\": 0.02, \"batch_size\": 64, \"epochs\": 40,\n",
        "      \"augment\": True, \"weighted_sampler\": False, \"freeze_backbone\": True,\n",
        "      \"label_smoothing\": 0.1, \"lr_schedule\": \"cosine\", \"warmup_ratio\": 0.1, \"seed\": 7},\n",
        "\n",
        "      {\"run_name\": \"S_noaug_lr1e-5_b32_e60_wd0.01_freezeN_accum4\",\n",
        "      \"lr\": 1e-5, \"weight_decay\": 0.01, \"batch_size\": 32, \"epochs\": 60,\n",
        "      \"augment\": False, \"weighted_sampler\": False, \"freeze_backbone\": False,\n",
        "      \"label_smoothing\": 0.0, \"lr_schedule\": \"cosine\", \"warmup_ratio\": 0.0, \"grad_accum\": 4, \"seed\": 42},\n",
        "]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ALL_RESULTS = []\n",
        "    for cfg in SWEEP:\n",
        "        res = run_experiment(cfg)\n",
        "        ALL_RESULTS.append(res)\n",
        "\n",
        "    summary = []\n",
        "    for r in ALL_RESULTS:\n",
        "        cfg = r[\"config\"]\n",
        "        test = r[\"test_metrics\"]\n",
        "        summary.append({\n",
        "            \"run_name\": cfg[\"run_name\"],\n",
        "            \"lr\": cfg[\"lr\"],\n",
        "            \"batch_size\": cfg[\"batch_size\"],\n",
        "            \"epochs\": cfg[\"epochs\"],\n",
        "            \"weight_decay\": cfg[\"weight_decay\"],\n",
        "            \"augment\": cfg[\"augment\"],\n",
        "            \"freeze_backbone\": cfg[\"freeze_backbone\"],\n",
        "            \"weighted_sampler\": cfg.get(\"weighted_sampler\", False),\n",
        "            \"label_smoothing\": cfg.get(\"label_smoothing\", 0.0),\n",
        "            \"seed\": cfg.get(\"seed\", RANDOM_SEED),\n",
        "            \"test_acc\": test.get(\"accuracy\"),\n",
        "            \"test_auc\": test.get(\"auc\"),\n",
        "            \"test_f1_w\": test.get(\"f1_weighted\"),\n",
        "            \"test_f1_m\": test.get(\"f1_macro\"),\n",
        "            \"test_prec_m\": test.get(\"precision_macro\"),\n",
        "            \"test_rec_m\": test.get(\"recall_macro\"),\n",
        "        })\n",
        "\n",
        "    with open(os.path.join(RESULTS_ROOT, \"sweep_summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"\\n Sweep complete. Summary saved to\", os.path.join(RESULTS_ROOT, \"sweep_summary.json\"))\n"
      ]
    }
  ]
}